{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-6ShtCgYhYF"
      },
      "source": [
        "# Clone the Github Repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_GacBejckVX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85fa1959-2c4c-49a4-8f43-6b9e3ded8eae"
      },
      "source": [
        "! git clone https://github.com/yungyuchen521/Graduation_Project.git\n",
        "! ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Graduation_Project'...\n",
            "remote: Enumerating objects: 2088, done.\u001b[K\n",
            "remote: Counting objects: 100% (1271/1271), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1235/1235), done.\u001b[K\n",
            "remote: Total 2088 (delta 38), reused 1265 (delta 36), pack-reused 817\u001b[K\n",
            "Receiving objects: 100% (2088/2088), 89.78 MiB | 31.39 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n",
            "Graduation_Project  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX4nvTdoalVI"
      },
      "source": [
        "# Extract the Selected People"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEg7G6ioYrKu"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qWUufg16X9L0",
        "outputId": "a50f03f0-529f-4e69-9bf0-934fbca5ff0d"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/yungyuchen521/Graduation_Project/main/names.txt', sep='\\t', header=None)\n",
        "df.columns = ['name', 'count']\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AJ_Cook</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AJ_Lamas</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Aaron_Eckhart</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aaron_Guiel</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Aaron_Patterson</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              name  count\n",
              "0          AJ_Cook      1\n",
              "1         AJ_Lamas      1\n",
              "2    Aaron_Eckhart      1\n",
              "3      Aaron_Guiel      1\n",
              "4  Aaron_Patterson      1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "vNaFr0QYaUOS",
        "outputId": "e51ce40b-1a42-41ec-a225-c525770a2883"
      },
      "source": [
        "N = 20 # select top n people with most images\n",
        "\n",
        "df = df.sort_values(by=['count'], ascending=False).iloc[:N, :]\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1871</th>\n",
              "      <td>George_W_Bush</td>\n",
              "      <td>530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1047</th>\n",
              "      <td>Colin_Powell</td>\n",
              "      <td>236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5458</th>\n",
              "      <td>Tony_Blair</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1404</th>\n",
              "      <td>Donald_Rumsfeld</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1892</th>\n",
              "      <td>Gerhard_Schroeder</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>Ariel_Sharon</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2175</th>\n",
              "      <td>Hugo_Chavez</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2941</th>\n",
              "      <td>Junichiro_Koizumi</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2468</th>\n",
              "      <td>Jean_Chretien</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2682</th>\n",
              "      <td>John_Ashcroft</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2288</th>\n",
              "      <td>Jacques_Chirac</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4963</th>\n",
              "      <td>Serena_Williams</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>Vladimir_Putin</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3401</th>\n",
              "      <td>Luiz_Inacio_Lula_da_Silva</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1933</th>\n",
              "      <td>Gloria_Macapagal_Arroyo</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2507</th>\n",
              "      <td>Jennifer_Capriati</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>Arnold_Schwarzenegger</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3202</th>\n",
              "      <td>Laura_Bush</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3351</th>\n",
              "      <td>Lleyton_Hewitt</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2044</th>\n",
              "      <td>Hans_Blix</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           name  count\n",
              "1871              George_W_Bush    530\n",
              "1047               Colin_Powell    236\n",
              "5458                 Tony_Blair    144\n",
              "1404            Donald_Rumsfeld    121\n",
              "1892          Gerhard_Schroeder    109\n",
              "373                Ariel_Sharon     77\n",
              "2175                Hugo_Chavez     71\n",
              "2941          Junichiro_Koizumi     60\n",
              "2468              Jean_Chretien     55\n",
              "2682              John_Ashcroft     53\n",
              "2288             Jacques_Chirac     52\n",
              "4963            Serena_Williams     52\n",
              "5569             Vladimir_Putin     49\n",
              "3401  Luiz_Inacio_Lula_da_Silva     48\n",
              "1933    Gloria_Macapagal_Arroyo     44\n",
              "2507          Jennifer_Capriati     42\n",
              "385       Arnold_Schwarzenegger     42\n",
              "3202                 Laura_Bush     41\n",
              "3351             Lleyton_Hewitt     41\n",
              "2044                  Hans_Blix     39"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbkpj025bTsF",
        "outputId": "0631308e-68c9-48be-b1cd-dfac24a3a3cc"
      },
      "source": [
        "people = df.set_index('name').T.to_dict('list')\n",
        "\n",
        "for key, value in people.items():\n",
        "  people[key] = people[key][0]\n",
        "  \n",
        "people"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Ariel_Sharon': 77,\n",
              " 'Arnold_Schwarzenegger': 42,\n",
              " 'Colin_Powell': 236,\n",
              " 'Donald_Rumsfeld': 121,\n",
              " 'George_W_Bush': 530,\n",
              " 'Gerhard_Schroeder': 109,\n",
              " 'Gloria_Macapagal_Arroyo': 44,\n",
              " 'Hans_Blix': 39,\n",
              " 'Hugo_Chavez': 71,\n",
              " 'Jacques_Chirac': 52,\n",
              " 'Jean_Chretien': 55,\n",
              " 'Jennifer_Capriati': 42,\n",
              " 'John_Ashcroft': 53,\n",
              " 'Junichiro_Koizumi': 60,\n",
              " 'Laura_Bush': 41,\n",
              " 'Lleyton_Hewitt': 41,\n",
              " 'Luiz_Inacio_Lula_da_Silva': 48,\n",
              " 'Serena_Williams': 52,\n",
              " 'Tony_Blair': 144,\n",
              " 'Vladimir_Putin': 49}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYnD6iztQxqM"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8CFEw8LciJ_"
      },
      "source": [
        "def get_file_name(name, num):\n",
        "  path = 'Graduation_Project/img/'\n",
        "  num = str(num)\n",
        "\n",
        "  while len(num) != 4:\n",
        "    num = '0' + num\n",
        "\n",
        "  return path + name + '/' + name + '_' + num + '.jpg'\n",
        "\n",
        "def get_all_img(map):\n",
        "  imgs = []\n",
        "  labels = []\n",
        "\n",
        "  for key, value in map.items():\n",
        "    for i in range(1, value+1):\n",
        "      jpg = Image.open(get_file_name(key, i))\n",
        "      imgs.append(np.array(jpg) / 255.0) # make the range within [0, 1]\n",
        "      jpg.close()\n",
        "\n",
        "      labels.append(key)\n",
        "\n",
        "  return np.array(imgs), np.array(labels)\n",
        "\n",
        "def horizontal_flip(img):\n",
        "  return np.flip(img, 1)\n",
        "\n",
        "# RAM crashes if doing augmentation\n",
        "def augmentation(data):\n",
        "  imgs, labels = data\n",
        "  aug_imgs = []\n",
        "  aug_labels = []\n",
        "\n",
        "  for i in range(len(labels)):\n",
        "    aug_imgs.append(imgs[i])\n",
        "    aug_imgs.append(horizontal_flip(imgs[i]))\n",
        "\n",
        "    aug_labels.append(labels[i])\n",
        "    aug_labels.append(labels[i])\n",
        "\n",
        "  return np.array(aug_imgs), np.array(aug_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "IP9QasF6k2Fa",
        "outputId": "6dc4c342-b303-4ace-acc1-1fe9e775c076"
      },
      "source": [
        "#imgs, labels = augmentation(get_all_img(people))\n",
        "imgs, labels = get_all_img(people)\n",
        "\n",
        "# check the images\n",
        "'''\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "  plt.subplot(5, 5, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(imgs[(i*123214 + 2021) % len(imgs)])\n",
        "\n",
        "plt.show()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nplt.figure(figsize=(10, 10))\\nfor i in range(25):\\n  plt.subplot(5, 5, i+1)\\n  plt.xticks([])\\n  plt.yticks([])\\n  plt.grid(False)\\n  plt.imshow(imgs[(i*123214 + 2021) % len(imgs)])\\n\\nplt.show()\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGbhyTERQ4Gp"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y23hZJOAVTOD",
        "outputId": "6021acbf-dacd-40fc-fb87-a08bd516d245"
      },
      "source": [
        "tmp = LabelEncoder().fit_transform(labels)\n",
        "tmp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 7, 7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiGqF7p5TyGj",
        "outputId": "1e05c245-c58f-4162-85a7-7f0ee088a0d5"
      },
      "source": [
        "Y = np.array(pd.get_dummies(tmp))\n",
        "\n",
        "Y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1906, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6pjD4PhQ_Kn"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(imgs, Y, test_size=0.33, stratify=Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCqmftG5cLi7"
      },
      "source": [
        "# Target-Agnostic Attack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drU7KsZ8cVne"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Input, Activation, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-I7Bocys7K3",
        "outputId": "ec2c5463-cd98-45a2-e021-8c6e43f05342"
      },
      "source": [
        "vgg = VGG16(include_top=False, weights='imagenet', input_tensor=Input(shape=x_train[0].shape))\n",
        "vgg.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 250, 250, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 250, 250, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 250, 250, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 125, 125, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 125, 125, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 125, 125, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 62, 62, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 62, 62, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 62, 62, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 62, 62, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 31, 31, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 31, 31, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 31, 31, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 31, 31, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 15, 15, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 15, 15, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFuPRTEBsG0M"
      },
      "source": [
        "for layer in vgg.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6Fl85Wct4E3",
        "outputId": "330d7909-eee1-4007-9400-43dcc7955409"
      },
      "source": [
        "model = Sequential([\n",
        "  vgg,\n",
        "  Flatten(),\n",
        "  Dropout(0.1),\n",
        "  Dense(64, activation='relu'),\n",
        "  Dropout(0.1),\n",
        "  Dense(32, activation='relu'),\n",
        "  Dropout(0.1),\n",
        "  Dense(N),\n",
        "  Activation('softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                1605696   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 20)                660       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 20)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16,323,124\n",
            "Trainable params: 1,608,436\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2rfWZ8KMtNe"
      },
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics='accuracy'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcmYeU-bNmvB",
        "outputId": "fd7260fb-d120-483c-c903-a3681e950000"
      },
      "source": [
        "checkpoint = ModelCheckpoint('best_model', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callback_list = [checkpoint]\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=20,\n",
        "    validation_data = (x_test, y_test),\n",
        "    epochs = 25,\n",
        "    callbacks = callback_list\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 2.6074 - accuracy: 0.2608\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.44038, saving model to best_model\n",
            "INFO:tensorflow:Assets written to: best_model/assets\n",
            "64/64 [==============================] - 56s 712ms/step - loss: 2.6074 - accuracy: 0.2608 - val_loss: 1.9490 - val_accuracy: 0.4404\n",
            "Epoch 2/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.8484 - accuracy: 0.4495\n",
            "Epoch 00002: val_accuracy improved from 0.44038 to 0.55803, saving model to best_model\n",
            "INFO:tensorflow:Assets written to: best_model/assets\n",
            "64/64 [==============================] - 32s 499ms/step - loss: 1.8484 - accuracy: 0.4495 - val_loss: 1.5598 - val_accuracy: 0.5580\n",
            "Epoch 3/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 1.2627 - accuracy: 0.6139\n",
            "Epoch 00003: val_accuracy improved from 0.55803 to 0.66932, saving model to best_model\n",
            "INFO:tensorflow:Assets written to: best_model/assets\n",
            "64/64 [==============================] - 32s 497ms/step - loss: 1.2627 - accuracy: 0.6139 - val_loss: 1.2051 - val_accuracy: 0.6693\n",
            "Epoch 4/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.9372 - accuracy: 0.7087\n",
            "Epoch 00004: val_accuracy improved from 0.66932 to 0.73132, saving model to best_model\n",
            "INFO:tensorflow:Assets written to: best_model/assets\n",
            "64/64 [==============================] - 32s 500ms/step - loss: 0.9372 - accuracy: 0.7087 - val_loss: 0.9378 - val_accuracy: 0.7313\n",
            "Epoch 5/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.6542 - accuracy: 0.7956\n",
            "Epoch 00005: val_accuracy did not improve from 0.73132\n",
            "64/64 [==============================] - 27s 430ms/step - loss: 0.6542 - accuracy: 0.7956 - val_loss: 1.0122 - val_accuracy: 0.7043\n",
            "Epoch 6/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.5306 - accuracy: 0.8316\n",
            "Epoch 00006: val_accuracy improved from 0.73132 to 0.74404, saving model to best_model\n",
            "INFO:tensorflow:Assets written to: best_model/assets\n",
            "64/64 [==============================] - 32s 496ms/step - loss: 0.5306 - accuracy: 0.8316 - val_loss: 0.9041 - val_accuracy: 0.7440\n",
            "Epoch 7/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.4539 - accuracy: 0.8559\n",
            "Epoch 00007: val_accuracy improved from 0.74404 to 0.78537, saving model to best_model\n",
            "INFO:tensorflow:Assets written to: best_model/assets\n",
            "64/64 [==============================] - 31s 493ms/step - loss: 0.4539 - accuracy: 0.8559 - val_loss: 0.7418 - val_accuracy: 0.7854\n",
            "Epoch 8/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.3637 - accuracy: 0.8865\n",
            "Epoch 00008: val_accuracy did not improve from 0.78537\n",
            "64/64 [==============================] - 27s 431ms/step - loss: 0.3637 - accuracy: 0.8865 - val_loss: 0.7260 - val_accuracy: 0.7822\n",
            "Epoch 9/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.2928 - accuracy: 0.9107\n",
            "Epoch 00009: val_accuracy improved from 0.78537 to 0.81876, saving model to best_model\n",
            "INFO:tensorflow:Assets written to: best_model/assets\n",
            "64/64 [==============================] - 32s 500ms/step - loss: 0.2928 - accuracy: 0.9107 - val_loss: 0.6234 - val_accuracy: 0.8188\n",
            "Epoch 10/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.2513 - accuracy: 0.9272\n",
            "Epoch 00010: val_accuracy did not improve from 0.81876\n",
            "64/64 [==============================] - 27s 431ms/step - loss: 0.2513 - accuracy: 0.9272 - val_loss: 0.6768 - val_accuracy: 0.8045\n",
            "Epoch 11/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.2638 - accuracy: 0.9123\n",
            "Epoch 00011: val_accuracy improved from 0.81876 to 0.82353, saving model to best_model\n",
            "INFO:tensorflow:Assets written to: best_model/assets\n",
            "64/64 [==============================] - 32s 498ms/step - loss: 0.2638 - accuracy: 0.9123 - val_loss: 0.6398 - val_accuracy: 0.8235\n",
            "Epoch 12/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.9295\n",
            "Epoch 00012: val_accuracy improved from 0.82353 to 0.82512, saving model to best_model\n",
            "INFO:tensorflow:Assets written to: best_model/assets\n",
            "64/64 [==============================] - 32s 496ms/step - loss: 0.2232 - accuracy: 0.9295 - val_loss: 0.6407 - val_accuracy: 0.8251\n",
            "Epoch 13/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.9381\n",
            "Epoch 00013: val_accuracy improved from 0.82512 to 0.82671, saving model to best_model\n",
            "INFO:tensorflow:Assets written to: best_model/assets\n",
            "64/64 [==============================] - 32s 501ms/step - loss: 0.2017 - accuracy: 0.9381 - val_loss: 0.6283 - val_accuracy: 0.8267\n",
            "Epoch 14/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.1977 - accuracy: 0.9413\n",
            "Epoch 00014: val_accuracy improved from 0.82671 to 0.84738, saving model to best_model\n",
            "INFO:tensorflow:Assets written to: best_model/assets\n",
            "64/64 [==============================] - 32s 499ms/step - loss: 0.1977 - accuracy: 0.9413 - val_loss: 0.5727 - val_accuracy: 0.8474\n",
            "Epoch 15/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.1451 - accuracy: 0.9522\n",
            "Epoch 00015: val_accuracy did not improve from 0.84738\n",
            "64/64 [==============================] - 27s 432ms/step - loss: 0.1451 - accuracy: 0.9522 - val_loss: 0.6018 - val_accuracy: 0.8331\n",
            "Epoch 16/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.9624\n",
            "Epoch 00016: val_accuracy did not improve from 0.84738\n",
            "64/64 [==============================] - 27s 431ms/step - loss: 0.1229 - accuracy: 0.9624 - val_loss: 0.7094 - val_accuracy: 0.8013\n",
            "Epoch 17/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.1518 - accuracy: 0.9460\n",
            "Epoch 00017: val_accuracy did not improve from 0.84738\n",
            "64/64 [==============================] - 27s 430ms/step - loss: 0.1518 - accuracy: 0.9460 - val_loss: 0.6115 - val_accuracy: 0.8315\n",
            "Epoch 18/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.9616\n",
            "Epoch 00018: val_accuracy did not improve from 0.84738\n",
            "64/64 [==============================] - 27s 431ms/step - loss: 0.1197 - accuracy: 0.9616 - val_loss: 0.7016 - val_accuracy: 0.8140\n",
            "Epoch 19/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.9632\n",
            "Epoch 00019: val_accuracy did not improve from 0.84738\n",
            "64/64 [==============================] - 27s 431ms/step - loss: 0.1095 - accuracy: 0.9632 - val_loss: 0.6089 - val_accuracy: 0.8474\n",
            "Epoch 20/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.9648\n",
            "Epoch 00020: val_accuracy did not improve from 0.84738\n",
            "64/64 [==============================] - 27s 431ms/step - loss: 0.1274 - accuracy: 0.9648 - val_loss: 0.7960 - val_accuracy: 0.8060\n",
            "Epoch 21/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9530\n",
            "Epoch 00021: val_accuracy did not improve from 0.84738\n",
            "64/64 [==============================] - 27s 431ms/step - loss: 0.1321 - accuracy: 0.9530 - val_loss: 0.6497 - val_accuracy: 0.8283\n",
            "Epoch 22/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.1267 - accuracy: 0.9577\n",
            "Epoch 00022: val_accuracy did not improve from 0.84738\n",
            "64/64 [==============================] - 27s 431ms/step - loss: 0.1267 - accuracy: 0.9577 - val_loss: 0.6855 - val_accuracy: 0.7965\n",
            "Epoch 23/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.9640\n",
            "Epoch 00023: val_accuracy did not improve from 0.84738\n",
            "64/64 [==============================] - 27s 431ms/step - loss: 0.1149 - accuracy: 0.9640 - val_loss: 0.6693 - val_accuracy: 0.8362\n",
            "Epoch 24/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.1416 - accuracy: 0.9593\n",
            "Epoch 00024: val_accuracy did not improve from 0.84738\n",
            "64/64 [==============================] - 27s 430ms/step - loss: 0.1416 - accuracy: 0.9593 - val_loss: 0.7404 - val_accuracy: 0.8045\n",
            "Epoch 25/25\n",
            "64/64 [==============================] - ETA: 0s - loss: 0.1273 - accuracy: 0.9585\n",
            "Epoch 00025: val_accuracy did not improve from 0.84738\n",
            "64/64 [==============================] - 27s 431ms/step - loss: 0.1273 - accuracy: 0.9585 - val_loss: 0.6735 - val_accuracy: 0.8140\n"
          ]
        }
      ]
    }
  ]
}